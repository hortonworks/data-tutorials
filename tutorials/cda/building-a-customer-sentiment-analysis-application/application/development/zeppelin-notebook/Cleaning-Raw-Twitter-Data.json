{"paragraphs":[{"text":"%spark2\nimport org.apache.spark._\nimport org.apache.spark.rdd._\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.mllib.feature.HashingTF\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.tree.GradientBoostedTrees\nimport org.apache.spark.mllib.tree.configuration.BoostingStrategy\nimport org.apache.spark._\nimport org.apache.spark.rdd._\nimport org.apache.spark.SparkContext._\nimport scala.util.{Success, Try}\n\n    val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n\n    var tweetDF = sqlContext.read.json(\"hdfs:///sandbox/tutorial-files/770/tweets_staging/*\")\n    tweetDF.show()","user":"anonymous","dateUpdated":"2018-09-18T13:00:19+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark._\nimport org.apache.spark.rdd._\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.mllib.feature.HashingTF\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.tree.GradientBoostedTrees\nimport org.apache.spark.mllib.tree.configuration.BoostingStrategy\nimport org.apache.spark._\nimport org.apache.spark.rdd._\nimport org.apache.spark.SparkContext._\nimport scala.util.{Success, Try}\nwarning: there was one deprecation warning; re-run with -deprecation for details\nsqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@7abbc7f4\ntweetDF: org.apache.spark.sql.DataFrame = [_corrupt_record: string, created_time: string ... 6 more fields]\n+---------------+--------------------+----------------+---------------+----+--------------------+--------------------+------------------+\n|_corrupt_record|        created_time|created_unixtime|    displayname|lang|                 msg|           time_zone|          tweet_id|\n+---------------+--------------------+----------------+---------------+----+--------------------+--------------------+------------------+\n|           null|Wed Mar 15 00:37:...|   1489538246855| amanda_obrien_|  en|when i was little...|                    |841810537394667520|\n|           null|Wed Mar 15 00:37:...|   1489538246983|   tinxdelacruz|  en|RT NashLenersOFC ...|             Beijing|841810537931456512|\n|           null|Wed Mar 15 00:37:...|   1489538247091|  esteladic2126|  es|RT Sugarlapin8 Te...|                    |841810538384384000|\n|           null|Wed Mar 15 00:37:...|   1489538247086|      _cabrisun|  en|poppinmahle happy...|Atlantic Time (Ca...|841810538363535360|\n|           null|Wed Mar 15 00:37:...|   1489538247093|    shabadoobie|  en|RT robinthede Rea...|Eastern Time (US ...|841810538392891392|\n|           null|Wed Mar 15 00:37:...|   1489538247076|   wompastompa1|  en|RT bwecht Happy B...|                    |841810538321612800|\n|           null|Wed Mar 15 00:37:...|   1489538247109|      NjDiestro|  tl|Happy birthday br...|                    |841810538459885568|\n|           null|Wed Mar 15 00:37:...|   1489538247233|     itschloooe|  en|How happy would u...|              London|841810538980089857|\n|           null|Wed Mar 15 00:37:...|   1489538247391|   paulinejoy97|  en|RT ohmybaequotes ...|                    |841810539642724353|\n|           null|Wed Mar 15 00:37:...|   1489538247248|5e1628bb947d498|  en|RT andibeth012 Si...|                    |841810539043004416|\n|           null|Wed Mar 15 00:37:...|   1489538247404|         dbsudg|  ja|【連載マンガ】「ほしとくずDont...|                    |841810539697201152|\n|           null|Wed Mar 15 00:37:...|   1489538247335|DrClarkIPresume|  en|RT KenJennings Th...|              Hawaii|841810539407908864|\n|           null|Wed Mar 15 00:37:...|   1489538247399|    kurokita666|  ja|RT 1717frappuccin...|                    |841810539676291072|\n|           null|Wed Mar 15 00:37:...|   1489538247522|     sherrygrey|  en|SusanSarandon So ...|                    |841810540192178176|\n|           null|Wed Mar 15 00:37:...|   1489538247456|       CTudor88|  en|Pet peeve its ven...|Eastern Time (US ...|841810539915415552|\n|           null|Wed Mar 15 00:37:...|   1489538247123| TheOfficialRK_|  en|Yo happy birthday...|Eastern Time (US ...|841810538518700034|\n|           null|Wed Mar 15 00:37:...|   1489538247618|     EricFundak|  en|RT richthekid Foc...|Pacific Time (US ...|841810540594925568|\n|           null|Wed Mar 15 00:37:...|   1489538247505|          bin99|  en|RT davidfrawleyve...|              Mumbai|841810540120969216|\n|           null|Wed Mar 15 00:37:...|   1489538247621|        yxzmin_|  es|RT carlosbugani s...|Pacific Time (US ...|841810540607467520|\n|           null|Wed Mar 15 00:37:...|   1489538247831|        Viffido|  en|RT bwecht Happy B...|             Caracas|841810541488267266|\n+---------------+--------------------+----------------+---------------+----+--------------------+--------------------+------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1537275569106_-1579760418","id":"20180918-125929_133276520","dateCreated":"2018-09-18T12:59:29+0000","dateStarted":"2018-09-18T13:00:19+0000","dateFinished":"2018-09-18T13:02:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:305"},{"text":"%spark2\nvar messages = tweetDF.select(\"msg\")\nprintln(\"Total messages: \" + messages.count())\n\nvar happyMessages = messages.filter(messages(\"msg\").contains(\"happy\"))\nval countHappy = happyMessages.count()\nprintln(\"Number of happy messages: \" +  countHappy)\n\nvar unhappyMessages = messages.filter(messages(\"msg\").contains(\" sad\"))\nval countUnhappy = unhappyMessages.count()\nprintln(\"Unhappy Messages: \" + countUnhappy)\n\nval smallest = Math.min(countHappy, countUnhappy).toInt\n\n//Create a dataset with equal parts happy and unhappy messages\nvar tweets = happyMessages.limit(smallest).unionAll(unhappyMessages.limit(smallest))","user":"anonymous","dateUpdated":"2018-09-18T13:05:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"messages: org.apache.spark.sql.DataFrame = [msg: string]\nTotal messages: 14440\nhappyMessages: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [msg: string]\ncountHappy: Long = 5351\nNumber of happy messages: 5351\nunhappyMessages: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [msg: string]\ncountUnhappy: Long = 1932\nUnhappy Messages: 1932\nsmallest: Int = 1932\nwarning: there was one deprecation warning; re-run with -deprecation for details\ntweets: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [msg: string]\n"}]},"apps":[],"jobName":"paragraph_1537275619650_947883325","id":"20180918-130019_1574630833","dateCreated":"2018-09-18T13:00:19+0000","dateStarted":"2018-09-18T13:05:50+0000","dateFinished":"2018-09-18T13:06:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:306"},{"text":"%spark2\nval messagesRDD = tweets.rdd\n//We use scala's Try to filter out tweets that couldn't be parsed\nval goodBadRecords = messagesRDD.map(\n  row =>{\n    Try{\n      val msg = row(0).toString.toLowerCase()\n      var isHappy:Int = 0\n      if(msg.contains(\" sad\")){\n        isHappy = 0\n      }else if(msg.contains(\"happy\")){\n        isHappy = 1\n      }\n      var msgSanitized = msg.replaceAll(\"happy\", \"\")\n      msgSanitized = msgSanitized.replaceAll(\"sad\",\"\")\n      //Return a tuple\n      (isHappy, msgSanitized.split(\" \").toSeq)\n    }\n  }\n)\n\n//We use this syntax to filter out exceptions\nval exceptions = goodBadRecords.filter(_.isFailure)\nprintln(\"total records with exceptions: \" + exceptions.count())\nexceptions.take(10).foreach(x => println(x.failed))\nvar labeledTweets = goodBadRecords.filter((_.isSuccess)).map(_.get)\nprintln(\"total records with successes: \" + labeledTweets.count())","user":"anonymous","dateUpdated":"2018-09-18T13:09:22+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"messagesRDD: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[44] at rdd at <console>:49\ngoodBadRecords: org.apache.spark.rdd.RDD[scala.util.Try[(Int, Seq[String])]] = MapPartitionsRDD[45] at map at <console>:50\nexceptions: org.apache.spark.rdd.RDD[scala.util.Try[(Int, Seq[String])]] = MapPartitionsRDD[46] at filter at <console>:51\ntotal records with exceptions: 0\nlabeledTweets: org.apache.spark.rdd.RDD[(Int, Seq[String])] = MapPartitionsRDD[48] at map at <console>:49\ntotal records with successes: 3864\n"}]},"apps":[],"jobName":"paragraph_1537275945249_1828464643","id":"20180918-130545_1363050434","dateCreated":"2018-09-18T13:05:45+0000","dateStarted":"2018-09-18T13:09:22+0000","dateFinished":"2018-09-18T13:09:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:307"},{"text":"%spark2\nlabeledTweets.take(10).foreach(x => println(x))","user":"anonymous","dateUpdated":"2018-09-18T13:14:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(1,WrappedArray(poppinmahle, , bday, pretty, girl😍🎈🎉))\n(1,WrappedArray(rt, robinthede, really, some, are, disappointed, that, maddow, only, has, 2005, like, you, would, only, be, , w/, 20, yrs, of, indepth, tax, analysis…))\n(1,WrappedArray(how, , would, u, be, if, you, could, be, shauna, for, one, —, i, think, id, be, so, , that, when, i, went, back, to, be, https//tco/h93kv9evge))\n(1,WrappedArray(rt, ohmybaequotes, being, single, is, different, from, being, alone, im, single, and, im, , with, it))\n(1,WrappedArray(【連載マンガ】「ほしとくずdont, worry, be, , chapter01」を読みました！人気マンガが無料で読める！lineマンガ今スグ読む→, https//tco/sjwmpvyiba, lineマンガ))\n(1,WrappedArray(yo, , birthday, homie, bmxandrewwhipps, https//tco/7ec4dzgzly))\n(1,WrappedArray(rt, richthekid, focus, on, what, makes, you))\n(1,WrappedArray(rt, krizzyfollman, take, risks, be, , stay, positive, , aldubxdtbytugofhearts))\n(1,WrappedArray(i, hope, youre))\n(1,WrappedArray(rt, 2jaespics, , couple, https//tco/dke7fyfzah))\n"}]},"apps":[],"jobName":"paragraph_1537276162468_-69426705","id":"20180918-130922_1602411326","dateCreated":"2018-09-18T13:09:22+0000","dateStarted":"2018-09-18T13:14:59+0000","dateFinished":"2018-09-18T13:15:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:308"},{"text":"%spark2\nval hashingTF = new HashingTF(2000)\n\n//Map the input strings to a tuple of labeled point + input text\nval input_labeled = (labeledTweets.map(\n  t => (t._1, hashingTF.transform(t._2)))\n  .map(x => new LabeledPoint((x._1).toDouble, x._2)))","user":"anonymous","dateUpdated":"2018-09-18T13:17:18+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"hashingTF: org.apache.spark.mllib.feature.HashingTF = org.apache.spark.mllib.feature.HashingTF@7a380904\ninput_labeled: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[50] at map at <console>:55\n"}]},"apps":[],"jobName":"paragraph_1537276498731_1914057332","id":"20180918-131458_775384874","dateCreated":"2018-09-18T13:14:58+0000","dateStarted":"2018-09-18T13:17:19+0000","dateFinished":"2018-09-18T13:17:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:309"},{"text":"%spark2\ninput_labeled.take(10).foreach(println)","user":"anonymous","dateUpdated":"2018-09-18T13:20:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(1.0,(2000,[405,775,1372,1754,1993],[1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[163,201,343,433,580,584,630,656,899,1138,1310,1320,1330,1371,1372,1400,1425,1433,1541,1543,1643,1746,1760],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[44,163,170,213,237,388,430,656,674,688,781,1036,1076,1329,1368,1371,1372,1425,1526,1564,1604,1760],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,4.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[333,374,433,495,531,682,777,1089,1281,1372,1567,1650,1921],[1.0,2.0,1.0,1.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[362,368,656,1258,1372,1715,1945],[1.0,1.0,1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[295,543,597,1023,1124,1372],[1.0,1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[82,433,479,526,1425,1690,1691],[1.0,1.0,1.0,1.0,1.0,1.0,1.0]))\n(1.0,(2000,[1,96,433,656,855,1140,1372,1809],[1.0,1.0,2.0,1.0,1.0,1.0,2.0,1.0]))\n(1.0,(2000,[0,1329,1472],[1.0,1.0,1.0]))\n(1.0,(2000,[433,910,1372,1426,1988],[1.0,1.0,1.0,1.0,1.0]))\n"}]},"apps":[],"jobName":"paragraph_1537276638317_1624942342","id":"20180918-131718_172860405","dateCreated":"2018-09-18T13:17:18+0000","dateStarted":"2018-09-18T13:20:54+0000","dateFinished":"2018-09-18T13:20:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:310"},{"text":"%spark2\n//We're keeping the raw text for inspection later\nvar sample = (labeledTweets.take(1000).map(\n  t => (t._1, hashingTF.transform(t._2), t._2))\n  .map(x => (new LabeledPoint((x._1).toDouble, x._2), x._3)))","user":"anonymous","dateUpdated":"2018-09-18T13:26:42+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sample: Array[(org.apache.spark.mllib.regression.LabeledPoint, Seq[String])] = Array(((1.0,(2000,[405,775,1372,1754,1993],[1.0,1.0,1.0,1.0,1.0])),WrappedArray(poppinmahle, \"\", bday, pretty, girl😍🎈🎉)), ((1.0,(2000,[163,201,343,433,580,584,630,656,899,1138,1310,1320,1330,1371,1372,1400,1425,1433,1541,1543,1643,1746,1760],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])),WrappedArray(rt, robinthede, really, some, are, disappointed, that, maddow, only, has, 2005, like, you, would, only, be, \"\", w/, 20, yrs, of, indepth, tax, analysis…)), ((1.0,(2000,[44,163,170,213,237,388,430,656,674,688,781,1036,1076,1329,1368,1371,1372,1425,1526,1564,1604,1760],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,4.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0])),Wrap..."}]},"apps":[],"jobName":"paragraph_1537276853425_-2141473555","id":"20180918-132053_1856911273","dateCreated":"2018-09-18T13:20:53+0000","dateStarted":"2018-09-18T13:26:44+0000","dateFinished":"2018-09-18T13:26:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:311"},{"text":"%spark2\n","user":"anonymous","dateUpdated":"2018-09-18T13:26:42+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1537277202906_-1507919643","id":"20180918-132642_1498280527","dateCreated":"2018-09-18T13:26:42+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:312"}],"name":"Cleaning-Raw-Twitter-Data","id":"2DQ197MEY","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}